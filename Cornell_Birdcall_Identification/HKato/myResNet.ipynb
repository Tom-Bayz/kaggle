{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import plotly.express as px\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import numpy as  np\n",
    "import librosa\n",
    "import cv2\n",
    "import warnings\n",
    "import IPython\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21375 entries, 0 to 21374\n",
      "Data columns (total 35 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   rating            21375 non-null  float64\n",
      " 1   playback_used     19575 non-null  object \n",
      " 2   ebird_code        21375 non-null  object \n",
      " 3   channels          21375 non-null  object \n",
      " 4   date              21375 non-null  object \n",
      " 5   pitch             21375 non-null  object \n",
      " 6   duration          21375 non-null  int64  \n",
      " 7   filename          21375 non-null  object \n",
      " 8   speed             21375 non-null  object \n",
      " 9   species           21375 non-null  object \n",
      " 10  number_of_notes   21375 non-null  object \n",
      " 11  title             21375 non-null  object \n",
      " 12  secondary_labels  21375 non-null  object \n",
      " 13  bird_seen         19575 non-null  object \n",
      " 14  sci_name          21375 non-null  object \n",
      " 15  location          21375 non-null  object \n",
      " 16  latitude          21375 non-null  object \n",
      " 17  sampling_rate     21375 non-null  object \n",
      " 18  type              21375 non-null  object \n",
      " 19  elevation         21375 non-null  object \n",
      " 20  description       15176 non-null  object \n",
      " 21  bitrate_of_mp3    21367 non-null  object \n",
      " 22  file_type         21375 non-null  object \n",
      " 23  volume            21375 non-null  object \n",
      " 24  background        8300 non-null   object \n",
      " 25  xc_id             21375 non-null  int64  \n",
      " 26  url               21375 non-null  object \n",
      " 27  country           21375 non-null  object \n",
      " 28  author            21375 non-null  object \n",
      " 29  primary_label     21375 non-null  object \n",
      " 30  longitude         21375 non-null  object \n",
      " 31  length            21375 non-null  object \n",
      " 32  time              21375 non-null  object \n",
      " 33  recordist         21375 non-null  object \n",
      " 34  license           21375 non-null  object \n",
      "dtypes: float64(1), int64(2), object(32)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./rawdata/train.csv\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "species=train.species.value_counts()\n",
    "birds=train.ebird_code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/264 [00:00<?, ?it/s]\n",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]\u001b[Ac:\\users\\owner\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- aldfly ----------------\n",
      "Audio Length: 25.488027210884354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|▊                                                                                 | 1/100 [00:01<03:04,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Length: 36.310204081632655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|█▋                                                                                | 2/100 [00:04<03:22,  2.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Length: 39.23591836734694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|██▍                                                                               | 3/100 [00:07<03:36,  2.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Length: 33.5934693877551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|███▎                                                                              | 4/100 [00:09<03:35,  2.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Length: 36.02285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|████                                                                              | 5/100 [00:11<03:41,  2.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Length: 7.784489795918367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|████▉                                                                             | 6/100 [00:12<02:48,  1.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Length: 45.40081632653061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|█████▋                                                                            | 7/100 [00:15<03:25,  2.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Length: 71.23591836734694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|██████▌                                                                           | 8/100 [00:20<04:38,  3.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Length: 26.253061224489795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                          | 0/264 [00:21<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c32b4fe4314a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0minterval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mcreate_split_stfit_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbirds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspecies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-c32b4fe4314a>\u001b[0m in \u001b[0;36mcreate_split_stfit_datasets\u001b[1;34m(birds, species, interval)\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0msub_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mXdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamplitude_to_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/{}/{}_{}_{}to{}sec.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbird_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbird_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1450\u001b[0m                                     \u001b[1;34m\"format specifier ('%s')\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m                                     % (str(X.dtype), format))\n\u001b[1;32m-> 1452\u001b[1;33m                 \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfooter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_split_stfit_datasets(birds, species, interval=5):\n",
    "    audio_dir_path=\"./rawdata/train_audio/\"\n",
    "    for bird_name in tqdm(birds):\n",
    "        print(\"---------------- {} ----------------\".format(bird_name))\n",
    "        if not os.path.exists(os.path.join('data', bird_name)):\n",
    "            os.mkdir(os.path.join('data', bird_name))\n",
    "        files = train[train.ebird_code==bird_name]['filename'].values\n",
    "        for file in tqdm(files, leave=False):\n",
    "            audio_path=os.path.join(audio_dir_path,bird_name,file)\n",
    "            x , sr = librosa.load(audio_path)\n",
    "            print(\"Audio Length: {}\".format(len(x) / sr))\n",
    "            i = 0\n",
    "            while ((i+interval) * sr < len(x)):\n",
    "                sub_x = x[i*sr:(i+interval)*sr]\n",
    "                sub_x = librosa.stft(sub_x)\n",
    "                Xdb = librosa.amplitude_to_db(abs(sub_x))\n",
    "                np.savetxt('./data/{}/{}_{}_{}to{}sec.csv'.format(bird_name, bird_name, file.split('.')[0], i, i+interval), Xdb)\n",
    "                i = i + interval\n",
    "\n",
    "interval = 5\n",
    "create_split_stfit_datasets(birds, species, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像のサイズ指定\n",
    "ScaleTo = 70\n",
    "seed = 7\n",
    "n_categories = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#トレーニングデータの読み込み\n",
    "data_dir =\"../input/train\"\n",
    "path = \"../input/train/*/*.png\"\n",
    "files = glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImg = []\n",
    "trainLabel = []\n",
    "j = 1\n",
    "num = len(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像データをリストに格納\n",
    "for img in files:\n",
    "    print(str(j) + \"/\" + str(num) , end=\"\\r\")\n",
    "    trainImg.append(cv2.resize(cv2.imread(img) ,(ScaleTo,ScaleTo)))\n",
    "    #trainLabel.append(img.split(\"/\")[-2])\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ラベルをリストに格納\n",
    "for dir in os.listdir(data_dir):\n",
    "    if dir == \".DS_Store\":\n",
    "        continue\n",
    "    dir1 = data_dir + \"/\" + dir\n",
    "    label = dir\n",
    "\n",
    "    for file in os.listdir(dir1):\n",
    "        if file != \"Thumbs.db\":\n",
    "\n",
    "            trainLabel.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kerasに渡すためにnumpy配列に変換。\n",
    "image_list = np.asarray(trainImg)\n",
    "label_list = pd.DataFrame(trainLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clearTrainImg = []\n",
    "examples = [];getEx = True\n",
    "\n",
    "for img in image_list:\n",
    "    #ぼかしを入れてノイズを除去\n",
    "    blurImg = cv2.GaussianBlur(img ,(5,5),0)\n",
    "    #RGBからHSVに変換\n",
    "    hsvImg = cv2.cvtColor(blurImg , cv2.COLOR_BGR2HSV)\n",
    "    #マスクを作成\n",
    "    lower_green = (25,40,50)\n",
    "    upper_green = (75,255,255)\n",
    "    mask = cv2.inRange(hsvImg , lower_green ,upper_green)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n",
    "    mask = cv2.morphologyEx(mask , cv2.MORPH_CLOSE,kernel)\n",
    "\n",
    "    #ブールマスクの作成\n",
    "    bMask = mask > 0\n",
    "\n",
    "    #マスクの適用\n",
    "    #空のイメージの作成\n",
    "    clear = np.zeros_like(img , np.uint8)\n",
    "    #オリジナル画像にブールマスクを適用\n",
    "    clear[bMask] = img[bMask]\n",
    "\n",
    "    clearTrainImg.append(clear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    plt.imshow(clearTrainImg[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clearTrainImg = np.asarray(clearTrainImg)\n",
    "clearTrainImg.shape\n",
    "# クラスの形式を変換\n",
    "le = LabelEncoder()\n",
    "le = le.fit(label_list)\n",
    "label_list = le.transform(label_list)\n",
    "label_list\n",
    "label_list = np_utils.to_categorical(label_list)\n",
    "label_list\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(clearTrainImg, label_list, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=180,  # randomly rotate images in the range\n",
    "        zoom_range = 0.1, # Randomly zoom image\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally\n",
    "        height_shift_range=0.1,  # randomly shift images vertically\n",
    "        horizontal_flip=True,  # randomly flip images horizontally\n",
    "        vertical_flip=True  # randomly flip images vertically\n",
    "    )\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデル作成・学習\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D,Input\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation,GlobalAveragePooling2D,Input\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "# ResNet50のロード。FC層は不要なので include_top=False\n",
    "input_tensor = Input(shape=(ScaleTo, ScaleTo, 3))\n",
    "resnet50 = ResNet50(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "# FC層の作成\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=resnet50.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "# ResNet50とFC層を結合してモデルを作成\n",
    "resnet50_model = Model(input=resnet50.input, output=top_model(resnet50.output))\n",
    "\n",
    "#ResNet50の一部の重みを固定\n",
    "for layer in resnet50_model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 多クラス分類を指定\n",
    "resnet50_model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=optimizers.SGD(lr=1e-3, momentum=0.9),\n",
    "          metrics=['accuracy'])\n",
    "resnet50_model.summary()\n",
    "\n",
    "\n",
    "#学習の実行\n",
    "hist = resnet50_model.fit_generator(datagen.flow(X_train, y_train, batch_size=75),\n",
    "                        epochs=35, validation_data=(X_test, y_test),\n",
    "                        steps_per_epoch=X_train.shape[0])\n",
    "\n",
    "\n",
    "                        steps_per_epoch=X_train.shape[0])\n",
    "\n",
    "\n",
    "#モデルの評価\n",
    "print(resnet50_model.evaluate(X_train, y_train)) #トレーニングの精度\n",
    "print(resnet50_model.evaluate(X_test, y_test))  #テスト精度\n",
    "\n",
    "\n",
    "#パラメータの保存\n",
    "model.save_weights('../content/weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
