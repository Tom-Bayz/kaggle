{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Real or Not? NLP with Disaster Tweets**<br>\n",
    "https://www.kaggle.com/c/nlp-getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import numba\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== training data =====\n",
      "         id keyword location  \\\n",
      "0         1     NaN      NaN   \n",
      "1         4     NaN      NaN   \n",
      "2         5     NaN      NaN   \n",
      "3         6     NaN      NaN   \n",
      "4         7     NaN      NaN   \n",
      "...     ...     ...      ...   \n",
      "7608  10869     NaN      NaN   \n",
      "7609  10870     NaN      NaN   \n",
      "7610  10871     NaN      NaN   \n",
      "7611  10872     NaN      NaN   \n",
      "7612  10873     NaN      NaN   \n",
      "\n",
      "                                                   text  target  \n",
      "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
      "1                Forest fire near La Ronge Sask. Canada       1  \n",
      "2     All residents asked to 'shelter in place' are ...       1  \n",
      "3     13,000 people receive #wildfires evacuation or...       1  \n",
      "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
      "...                                                 ...     ...  \n",
      "7608  Two giant cranes holding a bridge collapse int...       1  \n",
      "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
      "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
      "7611  Police investigating after an e-bike collided ...       1  \n",
      "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
      "\n",
      "[7613 rows x 5 columns]\n",
      "id           0.000000\n",
      "keyword      0.801261\n",
      "location    33.272035\n",
      "text         0.000000\n",
      "target       0.000000\n",
      "dtype: float64\n",
      "\n",
      "===== test data =====\n",
      "         id keyword location  \\\n",
      "0         1     NaN      NaN   \n",
      "1         4     NaN      NaN   \n",
      "2         5     NaN      NaN   \n",
      "3         6     NaN      NaN   \n",
      "4         7     NaN      NaN   \n",
      "...     ...     ...      ...   \n",
      "7608  10869     NaN      NaN   \n",
      "7609  10870     NaN      NaN   \n",
      "7610  10871     NaN      NaN   \n",
      "7611  10872     NaN      NaN   \n",
      "7612  10873     NaN      NaN   \n",
      "\n",
      "                                                   text  target  \n",
      "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
      "1                Forest fire near La Ronge Sask. Canada       1  \n",
      "2     All residents asked to 'shelter in place' are ...       1  \n",
      "3     13,000 people receive #wildfires evacuation or...       1  \n",
      "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
      "...                                                 ...     ...  \n",
      "7608  Two giant cranes holding a bridge collapse int...       1  \n",
      "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
      "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
      "7611  Police investigating after an e-bike collided ...       1  \n",
      "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
      "\n",
      "[7613 rows x 5 columns]\n",
      "id           0.000000\n",
      "keyword      0.801261\n",
      "location    33.272035\n",
      "text         0.000000\n",
      "target       0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('rawdata/train.csv')\n",
    "test = pd.read_csv('rawdata/train.csv')\n",
    "\n",
    "\n",
    "df = train\n",
    "print(\"===== training data =====\")\n",
    "print(df)\n",
    "print(df.isna().sum()/len(df)*100)\n",
    "print()\n",
    "\n",
    "df = test\n",
    "print(\"===== test data =====\")\n",
    "print(df)\n",
    "print(df.isna().sum()/len(df)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欠損値が多すぎて, locationが現時点で使えなさそう."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Exploring the data distribution of tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yonezu.t/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "Logistic Regression ROC Auc Score with TFIDF - 0.788262\n",
      "F1Score - 0.750000\n",
      "Logistic Regression Roc AUC Score with countvectorizer - 0.790358\n",
      "/Users/yonezu.t/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Description</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Basic LR Model - Basline - TFIDF</td>\n",
       "      <td>0.786502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Basic LR Model - Basline - CV</td>\n",
       "      <td>0.789852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Basic LR Model - Basline - TFIDF</td>\n",
       "      <td>0.787483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Basic LR Model - Basline - CV</td>\n",
       "      <td>0.769207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Basic LR Model - Basline - TFIDF</td>\n",
       "      <td>0.785452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Basic LR Model - Basline - CV</td>\n",
       "      <td>0.782244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Basic LR Model - Basline - TFIDF</td>\n",
       "      <td>0.798910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Basic LR Model - Basline - CV</td>\n",
       "      <td>0.797844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Basic LR Model - Basline - TFIDF</td>\n",
       "      <td>0.782481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Basic LR Model - Basline - CV</td>\n",
       "      <td>0.790973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Basic LR Model - Basline - TFIDF</td>\n",
       "      <td>0.809157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Basic LR Model - Basline - CV</td>\n",
       "      <td>0.801311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Basic LR Model - Basline - TFIDF</td>\n",
       "      <td>0.778389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Basic LR Model - Basline - CV</td>\n",
       "      <td>0.790587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Basic LR Model - Basline - TFIDF</td>\n",
       "      <td>0.770882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Basic LR Model - Basline - CV</td>\n",
       "      <td>0.775053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Basic LR Model - Basline - TFIDF</td>\n",
       "      <td>0.805351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Basic LR Model - Basline - CV</td>\n",
       "      <td>0.802149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Basic LR Model - Basline - TFIDF</td>\n",
       "      <td>0.788262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Basic LR Model - Basline - CV</td>\n",
       "      <td>0.790358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Description     Score\n",
       "0   Basic LR Model - Basline - TFIDF  0.786502\n",
       "1      Basic LR Model - Basline - CV  0.789852\n",
       "2   Basic LR Model - Basline - TFIDF  0.787483\n",
       "3      Basic LR Model - Basline - CV  0.769207\n",
       "4   Basic LR Model - Basline - TFIDF  0.785452\n",
       "5      Basic LR Model - Basline - CV  0.782244\n",
       "6   Basic LR Model - Basline - TFIDF  0.798910\n",
       "7      Basic LR Model - Basline - CV  0.797844\n",
       "8   Basic LR Model - Basline - TFIDF  0.782481\n",
       "9      Basic LR Model - Basline - CV  0.790973\n",
       "10  Basic LR Model - Basline - TFIDF  0.809157\n",
       "11     Basic LR Model - Basline - CV  0.801311\n",
       "12  Basic LR Model - Basline - TFIDF  0.778389\n",
       "13     Basic LR Model - Basline - CV  0.790587\n",
       "14  Basic LR Model - Basline - TFIDF  0.770882\n",
       "15     Basic LR Model - Basline - CV  0.775053\n",
       "16  Basic LR Model - Basline - TFIDF  0.805351\n",
       "17     Basic LR Model - Basline - CV  0.802149\n",
       "18  Basic LR Model - Basline - TFIDF  0.788262\n",
       "19     Basic LR Model - Basline - CV  0.790358"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 学習データをtrainとtestに分割する\n",
    "X_train,X_test,y_train,y_test = train_test_split(df_train['text'],df_train['target'])\n",
    "vector = TfidfVectorizer().fit(X_train)\n",
    "\n",
    "#print(vector.get_feature_names())\n",
    "X_train_vector = vector.transform(X_train)\n",
    "#print(X_train_vector.toarray())\n",
    "\n",
    "\n",
    "X_test_vector = vector.transform(X_test)\n",
    "#print(X_test_vector)\n",
    "model = LogisticRegression().fit(X_train_vector,y_train)\n",
    "print('Logistic Regression ROC Auc Score with TFIDF - %3f'%(roc_auc_score(y_test,model.predict(X_test_vector))))\n",
    "print('F1Score - %3f'%(f1_score(y_test,model.predict(X_test_vector))))\n",
    "score_df = score_df.append({'Model Description':'Basic LR Model - Basline - TFIDF',\n",
    "                           'Score':roc_auc_score(y_test,model.predict(X_test_vector))}\n",
    "                           ,ignore_index=True)\n",
    "\n",
    "####### Now let's try with count vectorizer\n",
    "\n",
    "cv_vector = CountVectorizer().fit(X_train)\n",
    "X_train_vector = cv_vector.transform(X_train)\n",
    "X_test_vector = cv_vector.transform(X_test)\n",
    "\n",
    "model = LogisticRegression().fit(X_train_vector,y_train)\n",
    "predict = model.predict(X_test_vector)\n",
    "score = roc_auc_score(y_test,predict)\n",
    "print('Logistic Regression Roc AUC Score with countvectorizer - %3f'%score)\n",
    "\n",
    "score_df = score_df.append({'Model Description':'Basic LR Model - Basline - CV',\n",
    "                          'Score':score}\n",
    "                          ,ignore_index=True)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Clean Data**  - So we have a baseline score of 79% to work with , let's get to clean data and see if we can improve the score\n",
    "\n",
    "As first step in cleaning - let us replace some commonly occuring shorthands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    import re\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"you'll\", \"you will\", text)\n",
    "    text = re.sub(r\"i'll\", \"i will\", text)\n",
    "    text = re.sub(r\"she'll\", \"she will\", text)\n",
    "    text = re.sub(r\"he'll\", \"he will\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"there's\", \"there is\", text)\n",
    "    text = re.sub(r\"here's\", \"here is\", text)\n",
    "    text = re.sub(r\"who's\", \"who is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"don't\", \"do not\", text)\n",
    "    text = re.sub(r\"shouldn't\", \"should not\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"   \", \" \", text) # Remove any extra spaces\n",
    "    return text\n",
    "\n",
    "\n",
    "df_train['clean_text'] = df_train['text'].apply(clean_text)\n",
    "df_test['clean_text'] = df_test['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we are going to do some further massaging which would make Job of Prediction Algorithm easy\n",
    "\n",
    "* Let us remove any characters other then alphabets\n",
    "* Convert all dictionary to lower case - for consistency \n",
    "* Lemmatize - More details on Stemming and Lemmatization [here](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we are going to store this text in a seperate column as we want to keep the orignal text in case we want to do some feature engineering down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yonezu.t/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/yonezu.t/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "\n",
    "def massage_text(text):\n",
    "    \n",
    "    \n",
    "    ## remove anything other then characters and put everything in lowercase\n",
    "    tweet = re.sub(\"[^a-zA-Z]\", ' ', text)\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.split()\n",
    "\n",
    "    \n",
    "    \n",
    "    lem = WordNetLemmatizer()\n",
    "    tweet = [lem.lemmatize(word) for word in tweet\n",
    "             if word not in set(stopwords.words('english'))]\n",
    "    tweet = ' '.join(tweet)\n",
    "    return tweet\n",
    "    print('--here goes nothing')\n",
    "    print(text)\n",
    "    print(tweet)\n",
    "\n",
    "df_train['clean_text'] = df_train['text'].apply(massage_text)\n",
    "df_test['clean_text'] = df_test['text'].apply(massage_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[0:10][['text','clean_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Creation of more Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Start by creating a Logistic Regression model again , this time we will use Grid Seach for hyper-parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vector = TfidfVectorizer().fit(df_train['clean_text'])\n",
    "df_train_vector = vector.transform(df_train['clean_text'])\n",
    "df_test_vector = vector.transform(df_test['clean_text'])\n",
    "lr_model = LogisticRegression()\n",
    "grid_values =  {'penalty':['l1', 'l2'],'C':[0.01, 0.1, 1, 10, 100]}\n",
    "grid_search_model = GridSearchCV(lr_model,param_grid=grid_values,cv=3)\n",
    "grid_search_model.fit(df_train_vector,df_train['target'])\n",
    "\n",
    "print(grid_search_model.best_estimator_)\n",
    "print(grid_search_model.best_score_)\n",
    "print(grid_search_model.best_params_)\n",
    "\n",
    "## dumping the output to a file \n",
    "predict_df = pd.DataFrame()\n",
    "predict = grid_search_model.predict(df_test_vector)\n",
    "predict_df['id'] = df_test['id']\n",
    "predict_df['target'] = predict\n",
    "predict_df.to_csv('sample_submission_2.csv', index=False)\n",
    "score_df = score_df.append({'Model Description':'LR Model - with data cleaning and Grid Search',\n",
    "                           'Score':grid_search_model.best_score_}\n",
    "                           ,ignore_index=True)\n",
    "\n",
    "\n",
    "### let's have another model with some ngram's though \n",
    "X_train,X_test,y_train,y_test = train_test_split(df_train['clean_text'],df_train['target'])\n",
    "vector = TfidfVectorizer(ngram_range=(1,3)).fit(X_train)\n",
    "X_train_vector = vector.transform(X_train)\n",
    "X_test_vector = vector.transform(X_test)\n",
    "\n",
    "lr_model = LogisticRegression(C=1,penalty='l2').fit(X_train_vector,y_train)\n",
    "predict = lr_model.predict(X_test_vector)\n",
    "score = roc_auc_score(y_test,predict)\n",
    "print('Roc AUC curve for LR and TFIDF with ngrams  - %3f'%score)\n",
    "\n",
    "score_df = score_df.append({'Model Description':'LR Model - with ngram range',\n",
    "                           'Score':score}\n",
    "                           ,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "### let's have another model with some ngram's though \n",
    "X_train,X_test,y_train,y_test = train_test_split(df_train['clean_text'],df_train['target'])\n",
    "vector = TfidfVectorizer(ngram_range=(1,3)).fit(X_train)\n",
    "X_train_vector = vector.transform(X_train)\n",
    "X_test_vector = vector.transform(X_test)\n",
    "\n",
    "lr_model = LogisticRegression(C=1,penalty='l2').fit(X_train_vector,y_train)\n",
    "predict = lr_model.predict(X_test_vector)\n",
    "score = roc_auc_score(y_test,predict)\n",
    "print('Roc AUC curve for LR and TFIDF with ngrams  - %3f'%score)\n",
    "\n",
    "score_df = score_df.append({'Model Description':'LR Model - with ngram range',\n",
    "                           'Score':grid_search_model.score}\n",
    "                           ,ignore_index=True)\n",
    "\n",
    "vector = TfidfVectorizer(ngram_range=(1,3)).fit(df_train['clean_text'])\n",
    "X_train_vector = vector.transform(df_train['clean_text'])\n",
    "X_test_vector = vector.transform(df_test['clean_text'])\n",
    "lr_model = LogisticRegression(C=1,penalty='l2').fit(X_train_vector,df_train['target'])\n",
    "predict = lr_model.predict(X_test_vector)\n",
    "\n",
    "\n",
    "## dumping the output to a file \n",
    "predict_df = pd.DataFrame()\n",
    "predict_df['id'] = df_test['id']\n",
    "predict_df['target'] = predict\n",
    "predict_df.to_csv('sample_submission_001.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_test,predict_df['target']],axis=1)\n",
    "\n",
    "### you could dump this in a csv and do further analysis to check what\n",
    "### misclassifications are there manually ,observations could then be used \n",
    "### to further tweak stuff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Let's apply Gaussian NB to the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(df_train['clean_text'], df_train['target'], random_state=20)\n",
    "## Apply Tfidf tranformation\n",
    "vector = TfidfVectorizer().fit(X_train)\n",
    "X_train_vector = vector.transform(X_train)\n",
    "X_test_vector  = vector.transform(X_test)\n",
    "df_test_vector = vector.transform(df_test['clean_text'])\n",
    "\n",
    "gb_model= GaussianNB().fit(X_train_vector.todense(),y_train)\n",
    "predict = gb_model.predict(X_test_vector.todense())\n",
    "\n",
    "print('Roc AUC score - %3f'%(roc_auc_score(y_test,predict)))\n",
    "score_df = score_df.append({'Model Description':'Naive Bayes',\n",
    "                           'Score':roc_auc_score(y_test,predict)}\n",
    "                           ,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Support Vector Classifier - with Grid search to Optimize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "vector = TfidfVectorizer().fit(df_train['clean_text'])\n",
    "df_train_vector = vector.transform(df_train['clean_text'])\n",
    "df_test_vector = vector.transform(df_test['clean_text'])\n",
    "\n",
    "svc_model = SVC()\n",
    "grid_values={'kernel':['linear', 'poly', 'rbf'],'C':[0.001,0.01,1,10]}\n",
    "grid_search_model= GridSearchCV(svc_model,param_grid=grid_values,cv=3)\n",
    "grid_search_model.fit(df_train_vector,df_train['target'])\n",
    "\n",
    "print(grid_search_model.best_estimator_)\n",
    "print(grid_search_model.best_score_)\n",
    "print(grid_search_model.best_params_)\n",
    "\n",
    "score_df = score_df.append({'Model Description':'SVC - with Grid Search',\n",
    "                           'Score':grid_search_model.best_score_}\n",
    "                           ,ignore_index=True)\n",
    "\n",
    "predict = grid_search_model.predict(df_test_vector)\n",
    "predict_df = pd.DataFrame()\n",
    "predict_df['id'] = df_test['id']\n",
    "predict_df['target'] = predict\n",
    "\n",
    "# # print(predict_df.head(5))\n",
    "predict_df.to_csv('sample_submission_4.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at score_df which has scores of all models till now and let's sort the output in ascending based on the Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df[['Model Description','Score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please Upvote if you found the notebook usefull.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. More data cleaning/ Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########  Word Count\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# df_train\n",
    "\n",
    "\n",
    "\n",
    "df_train['word_count'] = df_train['text'].apply(lambda x : len(x.lower().split()))\n",
    "df_test['word_count'] = df_test['text'].apply(lambda x : len(x.lower().split()))\n",
    "\n",
    "\n",
    "print('Average word count for non-disaster tweet - %.3f \\\n",
    "      '%(df_train[df_train['target']==0]['word_count'].mean()))\n",
    "\n",
    "      \n",
    "print('Average word count for disaster tweet - %.3f \\\n",
    "      '%(df_train[df_train['target']==1]['word_count'].mean()))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x='target',y='word_count',data=df_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Unique Word Count\n",
    "\n",
    "df_train['u_word_count'] = df_train['text'].apply(lambda x : len(set(x.lower().split())))\n",
    "df_test['u_word_count'] = df_test['text'].apply(lambda x : len(set(x.lower().split())))\n",
    "\n",
    "print('Average word count for non disaster tweet - %.3f \\\n",
    "      '%(df_train[df_train['target']==0]['u_word_count'].mean()))\n",
    "\n",
    "      \n",
    "print('Average word count for disaster tweet - %.3f \\\n",
    "      '%(df_train[df_train['target']==1]['u_word_count'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Stop word count\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set (stopwords.words(\"english\"))\n",
    "temp ='here you go then'\n",
    "df_train['stop_word_count']=df_train['text'].apply(lambda x : \\\n",
    "                                                   len([w for w in x.split() if w in stop_words] ))\n",
    "df_test['stop_word_count']=df_test['text'].apply(lambda x : \\\n",
    "                                                   len([w for w in x.split() if w in stop_words] ))\n",
    "\n",
    "\n",
    "print('Average word count for non-disaster tweet - %.3f \\\n",
    "      '%(df_train[df_train['target']==0]['stop_word_count'].mean()))\n",
    "\n",
    "      \n",
    "print('Average word count for disaster tweet - %.3f \\\n",
    "      '%(df_train[df_train['target']==1]['stop_word_count'].mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### URL count\n",
    "import re\n",
    "\n",
    "\n",
    "df_train['url_count'] = df_train['text'].apply(lambda x: len(re.findall('http[s]*:',x)))\n",
    "df_test['url_count'] = df_test['text'].apply(lambda x: len(re.findall('http[s]*:',x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mean word length count \n",
    "\n",
    "df_train['mean_word_l_count'] = df_train.apply(lambda r : len(r['text'])/r['word_count'],axis=1)\n",
    "df_test['mean_word_l_count'] = df_test.apply(lambda r : len(r['text'])/r['word_count'],axis=1)\n",
    "\n",
    "\n",
    "print(df_test[['mean_word_l_count','text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hash_count  count\n",
    "\n",
    "df_train['hash_count'] = df_train['text'].apply(lambda x: len(re.findall('#',x)))\n",
    "df_test['hash_count'] = df_test['text'].apply(lambda x: len(re.findall('#',x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### mention count @\n",
    "\n",
    "\n",
    "## hash_count  count\n",
    "\n",
    "df_train['mention_count'] = df_train['text'].apply(lambda x: len(re.findall('@',x)))\n",
    "df_test['mention_count'] = df_test['text'].apply(lambda x: len(re.findall('@',x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "cores= multiprocessing.cpu_count()\n",
    "\n",
    "w2v_model = Word2Vec(min_count=5,\n",
    "                     window = 2,\n",
    "                     sample=6e-5,\n",
    "                     alpha=0.03,\n",
    "                     min_alpha=0.0007,\n",
    "                     workers=3\n",
    "                     )\n",
    "\n",
    "\n",
    "\n",
    "w2v_model.build_vocab(df_train['text'],progress_per=50)\n",
    "\n",
    "\n",
    "w2v_model.train(df_train['text'],total_examples=w2v_model.corpus_count,epochs=30,report_delay=1)\n",
    "\n",
    "w2v_model.init_sims(replace=True)\n",
    "\n",
    "print(w2v_model.wv.most_similar(positive=[\"closed\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
